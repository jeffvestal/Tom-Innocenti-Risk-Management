{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Index - \"The Zero-Config Setup\"\n",
    "\n",
    "## Innocenti Risk Management Enablement Kit\n",
    "\n",
    "---\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Setting up semantic search traditionally requires:\n",
    "1. Deploying an embedding model\n",
    "2. Managing vector dimensions and similarity metrics\n",
    "3. Writing ingest pipelines to generate embeddings\n",
    "4. Configuring dense vector fields\n",
    "\n",
    "### The Solution: Elastic Inference Service (EIS) + `semantic_text`\n",
    "\n",
    "With EIS, you get:\n",
    "- **One-click model deployment** via inference endpoints\n",
    "- **`semantic_text` field type** that auto-embeds at index time\n",
    "- **No pipeline configuration** - just index your documents\n",
    "\n",
    "**What we'll do:**\n",
    "1. Connect to Elastic Cloud\n",
    "2. Create a Jina Embeddings v3 inference endpoint\n",
    "3. Create an index with `semantic_text`\n",
    "4. Bulk index our EU AI Act articles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install elasticsearch python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from elasticsearch import Elasticsearch, BadRequestError\n",
    "from elasticsearch.helpers import bulk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our credential helper\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "from utils.credentials import setup_notebook, get_index_name, get_inference_id\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup credentials and display configuration\n",
    "creds = setup_notebook(require_elastic=True, require_jina=False)\n",
    "\n",
    "# Get unique names for this user\n",
    "INDEX_NAME = get_index_name(\"search-eu-ai-act\")\n",
    "INFERENCE_ID = get_inference_id(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Elastic Cloud\n",
    "\n",
    "We'll use the official Python client with Cloud ID authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "    cloud_id=creds[\"ELASTIC_CLOUD_ID\"],\n",
    "    api_key=creds[\"ELASTIC_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Verify connection\n",
    "info = es.info()\n",
    "print(f\"✓ Connected to Elasticsearch {info['version']['number']}\")\n",
    "print(f\"  Cluster: {info['cluster_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Inference Endpoint (Jina Embeddings v3)\n",
    "\n",
    "The inference endpoint is like a \"model service\" that Elasticsearch calls to generate embeddings.\n",
    "\n",
    "**Jina Embeddings v3 highlights:**\n",
    "- Multilingual (100+ languages)\n",
    "- Task-specific modes (retrieval, classification, etc.)\n",
    "- 1024 dimensions by default\n",
    "\n",
    "We'll wrap this in a try/except for idempotency - if the endpoint already exists, we continue gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_inference(es_client, inference_id: str) -> bool:\n",
    "    \"\"\"\n",
    "    Create a Jina Embeddings v3 inference endpoint.\n",
    "    \n",
    "    Handles ResourceAlreadyExists gracefully for idempotency.\n",
    "    \n",
    "    Args:\n",
    "        es_client: Elasticsearch client\n",
    "        inference_id: Unique ID for this inference endpoint\n",
    "    \n",
    "    Returns:\n",
    "        True if created, False if already existed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        es_client.inference.put(\n",
    "            inference_id=inference_id,\n",
    "            task_type=\"text_embedding\",\n",
    "            body={\n",
    "                \"service\": \"jinaai\",\n",
    "                \"service_settings\": {\n",
    "                    \"model_id\": \"jina-embeddings-v3\"\n",
    "                    # Note: API key can be set here or in Kibana\n",
    "                    # \"api_key\": \"your-jina-key\"  # Optional - can configure in Kibana\n",
    "                },\n",
    "                \"task_settings\": {\n",
    "                    \"task\": \"retrieval.passage\"  # Optimized for document retrieval\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        print(f\"✓ Created inference endpoint: {inference_id}\")\n",
    "        return True\n",
    "        \n",
    "    except BadRequestError as e:\n",
    "        if \"resource_already_exists_exception\" in str(e).lower() or \"already exists\" in str(e).lower():\n",
    "            print(f\"✓ Inference endpoint already exists: {inference_id}\")\n",
    "            return False\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding inference endpoint\n",
    "create_embedding_inference(es, INFERENCE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Index with `semantic_text`\n",
    "\n",
    "The `semantic_text` field type is the magic:\n",
    "- Automatically calls the inference endpoint at index time\n",
    "- Stores both the original text and the embeddings\n",
    "- Enables semantic search with zero configuration\n",
    "\n",
    "**Our schema:**\n",
    "- `article_number` - Keyword for filtering\n",
    "- `title` - Keyword + text for hybrid search\n",
    "- `text` - **semantic_text** for vector search\n",
    "- `language`, `url` - Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the index mapping\n",
    "INDEX_MAPPING = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"article_number\": {\n",
    "                \"type\": \"keyword\"  # Exact match for filtering\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",  # Full-text search on titles\n",
    "                \"fields\": {\n",
    "                    \"keyword\": {\"type\": \"keyword\"}  # Also exact match\n",
    "                }\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"semantic_text\",  # THE MAGIC FIELD\n",
    "                \"inference_id\": INFERENCE_ID  # Points to our Jina model\n",
    "            },\n",
    "            \"language\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"url\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Index mapping defined with semantic_text field\")\n",
    "print(f\"  Inference endpoint: {INFERENCE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index (delete if exists for clean re-runs)\n",
    "if es.indices.exists(index=INDEX_NAME):\n",
    "    print(f\"Index {INDEX_NAME} exists, deleting for fresh start...\")\n",
    "    es.indices.delete(index=INDEX_NAME)\n",
    "\n",
    "es.indices.create(index=INDEX_NAME, body=INDEX_MAPPING)\n",
    "print(f\"✓ Created index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Index Documents\n",
    "\n",
    "Now we'll load the JSON from Notebook 01 and bulk index it.\n",
    "\n",
    "**Note:** With `semantic_text`, embeddings are generated automatically at index time. This may take a moment for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the articles from Notebook 01\n",
    "data_file = Path.cwd().parent / \"data\" / \"eu_ai_act_clean.json\"\n",
    "\n",
    "if not data_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found: {data_file}\\n\"\n",
    "        \"Please run Notebook 01 first to generate the data.\"\n",
    "    )\n",
    "\n",
    "with open(data_file, 'r', encoding='utf-8') as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(articles)} articles from {data_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actions(articles: list, index_name: str):\n",
    "    \"\"\"\n",
    "    Generator for bulk indexing actions.\n",
    "    \n",
    "    Args:\n",
    "        articles: List of article dictionaries\n",
    "        index_name: Target index name\n",
    "    \n",
    "    Yields:\n",
    "        Bulk action dictionaries\n",
    "    \"\"\"\n",
    "    for article in articles:\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": article[\"id\"],  # Use article ID for idempotent indexing\n",
    "            \"_source\": {\n",
    "                \"article_number\": article[\"article_number\"],\n",
    "                \"title\": article[\"title\"],\n",
    "                \"text\": article[\"text\"],\n",
    "                \"language\": article.get(\"language\", \"en\"),\n",
    "                \"url\": article.get(\"url\", \"\")\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk index with progress bar\n",
    "print(f\"Indexing {len(articles)} articles to {INDEX_NAME}...\")\n",
    "print(\"(Embeddings are generated automatically - this may take a minute)\")\n",
    "\n",
    "success, errors = bulk(\n",
    "    es,\n",
    "    generate_actions(articles, INDEX_NAME),\n",
    "    chunk_size=10,  # Smaller chunks for semantic_text (embedding generation)\n",
    "    refresh=True    # Make documents immediately searchable\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Indexed {success} documents\")\n",
    "if errors:\n",
    "    print(f\"✗ {len(errors)} errors occurred\")\n",
    "    for error in errors[:5]:  # Show first 5 errors\n",
    "        print(f\"  - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verification\n",
    "\n",
    "Let's verify the indexing worked by running a test search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check document count\n",
    "count = es.count(index=INDEX_NAME)[\"count\"]\n",
    "print(f\"✓ Index {INDEX_NAME} contains {count} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test semantic search\n",
    "test_query = \"biometric identification systems\"\n",
    "\n",
    "results = es.search(\n",
    "    index=INDEX_NAME,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"semantic\": {\n",
    "                \"field\": \"text\",\n",
    "                \"query\": test_query\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5,\n",
    "        \"_source\": [\"article_number\", \"title\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Test Search: \\\"{test_query}\\\" ---\")\n",
    "print(f\"Found {results['hits']['total']['value']} matches\\n\")\n",
    "\n",
    "for i, hit in enumerate(results['hits']['hits'], 1):\n",
    "    print(f\"{i}. Article {hit['_source']['article_number']}: {hit['_source']['title'][:60]}\")\n",
    "    print(f\"   Score: {hit['_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Sample Document with Embeddings\n",
    "\n",
    "Let's peek at how `semantic_text` stores the embeddings internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample document to see the structure\n",
    "sample = es.get(index=INDEX_NAME, id=\"en_art_5\")\n",
    "\n",
    "print(\"--- Sample Document Structure ---\")\n",
    "print(f\"ID: {sample['_id']}\")\n",
    "print(f\"Article: {sample['_source']['article_number']}\")\n",
    "print(f\"Title: {sample['_source']['title']}\")\n",
    "print(f\"\\nText field type: {type(sample['_source']['text'])}\")\n",
    "\n",
    "# The semantic_text field contains both text and inference metadata\n",
    "if isinstance(sample['_source']['text'], dict):\n",
    "    print(\"\\nNote: semantic_text stores the original text plus embedding metadata\")\n",
    "    print(f\"Keys in text field: {list(sample['_source']['text'].keys()) if isinstance(sample['_source']['text'], dict) else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You've successfully:\n",
    "1. ✅ Connected to Elastic Cloud\n",
    "2. ✅ Created a Jina Embeddings v3 inference endpoint\n",
    "3. ✅ Created an index with `semantic_text`\n",
    "4. ✅ Bulk indexed the EU AI Act articles\n",
    "5. ✅ Verified with a semantic search\n",
    "\n",
    "**Continue to Notebook 03** to see how reranking with Jina Reranker v3 improves precision.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | What We Learned |\n",
    "|---------|----------------|\n",
    "| **EIS** | Elastic Inference Service = managed model endpoints |\n",
    "| **semantic_text** | Auto-embeds at index time, no pipelines needed |\n",
    "| **Idempotency** | Wrap `create_inference` in try/except for safe re-runs |\n",
    "| **Zero Config** | One field type + one inference ID = semantic search ready |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
